{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5e3a286-0b1f-44cf-896c-2d74fd299aea",
   "metadata": {},
   "source": [
    "### todo\n",
    "- \"newtrial_frame\", we might not need it in the future\n",
    "- save name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "025615e7-f05e-49a2-b73e-4e03b375016d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kilosort'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkilosort\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_ops\n\u001b[0;32m      7\u001b[0m date \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20250313\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Define Path and Load Files\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'kilosort'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "from pathlib import Path\n",
    "from kilosort.io import load_ops\n",
    "\n",
    "date = 20250313\n",
    "\n",
    "# Define Path and Load Files\n",
    "results_dir = Path(r'D:\\20250313\\kilosort_bankAB_phy')\n",
    "APtimestamps = np.load(r\"D:\\20250313\\2025-03-13_15-09-41\\Record Node 101\\experiment1\\recording1\\continuous\\Neuropix-PXI-100.ProbeA-AP\\timestamps.npy\")\n",
    "save_path = r'D:\\20250313\\zarya_20250313__bankAB_unit.mat'\n",
    "\n",
    "spike_clusters = np.load(results_dir / 'spike_clusters.npy')\n",
    "spike_times = np.load(results_dir / 'spike_times.npy')\n",
    "channel_positions = np.load(results_dir / 'channel_positions.npy')\n",
    "channel_map =  np.load(results_dir / 'channel_map.npy')\n",
    "templates =  np.load(results_dir / 'templates.npy')\n",
    "\n",
    "cluster_group = pd.read_csv(results_dir / 'cluster_info.tsv', sep='\\t')\n",
    "good_count = (cluster_group[\"group\"] == \"good\").sum()\n",
    "test = cluster_group[\"depth\"][0]\n",
    "print(f\"Number of 'good' clusters: {good_count}\")\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ce7bb5-238c-4ad0-a71d-fee92f04052f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eca0cd-56c7-4761-9fdd-27ca08e19326",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chan_best = (templates**2).sum(axis=1).argmax(axis=-1)\n",
    "chan_best = channel_map[chan_best]\n",
    "template_amplitudes = ((templates**2).sum(axis=(-2,-1))**0.5)\n",
    "uniq_spike_clusters = np.unique(spike_clusters)\n",
    "spike_counts = np.unique(spike_clusters, return_counts=True)[1]\n",
    "channel_y_positions = channel_positions[:, 1]\n",
    "newtrial_frame = np.where(np.diff(APtimestamps) < -1) [0]\n",
    "print(newtrial_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35f91570-6d0a-4beb-9f0e-2ac7ba676b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 15,  16,  24,  27,  28,  30,  34,  37,  39,  40,  41,  44,  51,\n",
       "        52,  55,  56,  73,  81,  85,  86,  87,  94,  96,  97,  99, 100,\n",
       "       102, 104, 105, 110, 117, 119, 121, 122, 132, 133, 168, 171, 172,\n",
       "       174, 207, 208, 209, 210, 211, 212, 213, 214, 217, 218, 219, 224,\n",
       "       227, 231, 232, 233, 250, 262, 263, 272, 290, 292, 295, 299, 308,\n",
       "       317, 321, 323, 326, 332, 334, 335, 336, 337, 338, 339, 340, 347,\n",
       "       352, 353, 356, 357, 372, 383, 395, 406, 409, 414, 415, 417, 435,\n",
       "       438, 439, 444, 447, 448, 449, 450, 451, 459, 460, 461, 462, 464,\n",
       "       465, 466, 468, 469, 470, 471, 473, 476, 478, 482, 489, 494, 499,\n",
       "       507, 508, 511, 512, 520, 522, 529, 531, 534, 536, 537, 540, 551,\n",
       "       558, 562, 570, 575, 576, 578, 580, 582, 588, 591, 593, 596, 597,\n",
       "       598, 609, 618, 622, 627, 631, 632, 635, 640, 641, 649, 655, 657,\n",
       "       658, 670, 673, 676, 677, 682, 684, 687, 688, 691, 692, 695, 696,\n",
       "       700, 702, 706, 714, 715, 719, 723, 724, 727, 728, 731, 732, 734,\n",
       "       738, 741, 742, 744, 745, 746, 748, 749, 751, 754, 755, 757, 758,\n",
       "       760, 761, 762, 763, 765, 766, 767, 768, 769])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniq_spike_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0978f5da-83e1-46dc-8257-93d0c05dd313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved at 'D:\\20250313\\zarya_20250313__bankAB_unit.mat'.\n"
     ]
    }
   ],
   "source": [
    "## 20250313 version\n",
    "\n",
    "depth = np.zeros(len(uniq_spike_clusters))\n",
    "group = np.zeros(len(uniq_spike_clusters))\n",
    "cluster_id = np.zeros(len(uniq_spike_clusters))\n",
    "ch = np.zeros(len(uniq_spike_clusters))\n",
    "spiketimes = {i: [] for i in range(len(uniq_spike_clusters))}\n",
    "\n",
    "\n",
    "for i, cluster in enumerate(uniq_spike_clusters):\n",
    "    idx = np.where(spike_clusters == cluster)\n",
    "    unit_kilo_frame  = spike_times[idx]\n",
    "\n",
    "    unit_spike_time = APtimestamps[unit_kilo_frame]\n",
    "    \n",
    "    cluster_id[i] = cluster\n",
    "    spiketimes[i].extend(unit_spike_time)\n",
    "    \n",
    "    depth[i] = cluster_group[\"depth\"][i]\n",
    "    group[i] = int(cluster_group.loc[cluster_group[\"cluster_id\"] == cluster, \"group\"].values[0] == \"good\")\n",
    "\n",
    "spiketimes = np.array([spiketimes[i] for i in range(len(uniq_spike_clusters))], dtype=object)\n",
    "units = {\n",
    "    'depth': depth,\n",
    "    'cluster_id': cluster_id,\n",
    "    'groups': group,\n",
    "    'spiketimes': spiketimes\n",
    "}\n",
    "\n",
    "scipy.io.savemat(save_path, {'units': units})\n",
    "\n",
    "print(f\"Data saved at '{save_path}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6077a66d-6dac-4ebd-bb82-37e03e0dbe27",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2117,) (0,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m idx \u001b[38;5;241m=\u001b[39m spike_clusters \u001b[38;5;241m==\u001b[39m cluster\n\u001b[0;32m     11\u001b[0m unit_kilo_frame  \u001b[38;5;241m=\u001b[39m spike_times[idx]\n\u001b[1;32m---> 12\u001b[0m trial_frame \u001b[38;5;241m=\u001b[39m (\u001b[43munit_kilo_frame\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnewtrial_frame\u001b[49m)\n\u001b[0;32m     13\u001b[0m unit_kilo_frame \u001b[38;5;241m=\u001b[39m unit_kilo_frame[trial_frame]\n\u001b[0;32m     15\u001b[0m unit_spike_time \u001b[38;5;241m=\u001b[39m APtimestamps[unit_kilo_frame]\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2117,) (0,) "
     ]
    }
   ],
   "source": [
    "## 20241220 version\n",
    "\n",
    "depth = np.zeros(len(uniq_spike_clusters))\n",
    "group = np.zeros(len(uniq_spike_clusters))\n",
    "cluster_id = np.zeros(len(uniq_spike_clusters))\n",
    "ch = np.zeros(len(uniq_spike_clusters))\n",
    "spiketimes = {i: [] for i in range(len(uniq_spike_clusters))}\n",
    "\n",
    "for i, cluster in enumerate(uniq_spike_clusters):\n",
    "    idx = spike_clusters == cluster\n",
    "    unit_kilo_frame  = spike_times[idx]\n",
    "    # trial_frame = (unit_kilo_frame >= newtrial_frame)\n",
    "    # unit_kilo_frame = unit_kilo_frame[trial_frame]\n",
    "\n",
    "    unit_spike_time = APtimestamps[unit_kilo_frame]\n",
    "    \n",
    "    cluster_id[i] = cluster\n",
    "    spiketimes[i].extend(unit_spike_time)\n",
    "    \n",
    "    chbest = chan_best[i]\n",
    "    ch[i] = chbest\n",
    "    depth[i] = channel_y_positions[chbest]\n",
    "    group[i] = \n",
    "\n",
    "spiketimes = np.array([spiketimes[i] for i in range(len(uniq_spike_clusters))], dtype=object)\n",
    "units = {\n",
    "    'depth': depth,\n",
    "    'ch': ch,\n",
    "    'cluster_id': cluster_id,\n",
    "    'spiketimes': spiketimes\n",
    "}\n",
    "\n",
    "scipy.io.savemat(save_path, {'units': units})\n",
    "\n",
    "print(f\"Data saved at '{save_path}'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
